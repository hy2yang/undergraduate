setwd("D:/workspace_r/CHNMap")
library(ggplot2)
library(mapproj)
library(plyr)
library(RColorBrewer)
#setwd("D:/BA/CHNMap")
CHNPop <-read.csv("ProvData.csv") #在ProvNames工作表中填入数字（本例为人口密度）然后另存为ProvData.csv
CHNmapdata<-read.csv("ProvMapData.csv")
ProvIndex<-read.csv("ProvIndex.csv")
Pop_Index <-merge(CHNPop,ProvIndex,by="ProvNames")
Pop_Index <-arrange(Pop_Index,ProvID)
Pop_Index <-transform(Pop_Index, ProvNames=NULL) #Pop_Index中的ProvNames对我们没用了，可以把这列删掉。
#删掉ProvNames这一列也可以使用语句：Pop_Index <- Pop_Index[,-1]
#不过这条语句不太直观你只知道删掉了第1列而不知道列名。
Pop_Map <- merge(CHNmapdata,Pop_Index,by.x="id",by.y="ProvID")
#合并Pop_Index和CHNmapdata，这样Mapdata中每个id就有Data列中的人口数据对应
Pop_Map <- arrange(Pop_Map,id,order) #经过合并操作之后数据被打乱，需要重新排序。
#先对id进行排序，然后对order进行排序
ggplot(Pop_Map, aes(x=long, y=lat, group=id, fill=PopData))+geom_polygon(colour="black")+coord_map()
#人口相差太大，自动上色看不出层次。需要手动进行调色。
install.packages("mapproj")
library(ggplot2)
library(mapproj)
library(plyr)
library(RColorBrewer)
#setwd("D:/BA/CHNMap")
CHNPop <-read.csv("ProvData.csv") #在ProvNames工作表中填入数字（本例为人口密度）然后另存为ProvData.csv
CHNmapdata<-read.csv("ProvMapData.csv")
ProvIndex<-read.csv("ProvIndex.csv")
Pop_Index <-merge(CHNPop,ProvIndex,by="ProvNames")
Pop_Index <-arrange(Pop_Index,ProvID)
Pop_Index <-transform(Pop_Index, ProvNames=NULL) #Pop_Index中的ProvNames对我们没用了，可以把这列删掉。
#删掉ProvNames这一列也可以使用语句：Pop_Index <- Pop_Index[,-1]
#不过这条语句不太直观你只知道删掉了第1列而不知道列名。
Pop_Map <- merge(CHNmapdata,Pop_Index,by.x="id",by.y="ProvID")
#合并Pop_Index和CHNmapdata，这样Mapdata中每个id就有Data列中的人口数据对应
Pop_Map <- arrange(Pop_Map,id,order) #经过合并操作之后数据被打乱，需要重新排序。
#先对id进行排序，然后对order进行排序
ggplot(Pop_Map, aes(x=long, y=lat, group=id, fill=PopData))+geom_polygon(colour="black")+coord_map()
#人口相差太大，自动上色看不出层次。需要手动进行调色。
Pop_Map$Pop_Scale <- cut(Pop_Map$PopData,breaks=c(0,50,150,250,300,400,600,1000,20000))
mymap <- ggplot(Pop_Map, aes(x=long, y=lat, group=id, fill=Pop_Scale))+geom_polygon(colour="black")+coord_map()
mymap
mymap+scale_fill_brewer(palette="Reds")
View(CHNPop)
mymap+scale_fill_brewer(palette="Greens")
Pop_Map$Pop_Scale <- cut(Pop_Map$PopData,breaks=c(0,50,100,150,250,300,400,500,600,700,800,1000,20000))
mymap <- ggplot(Pop_Map, aes(x=long, y=lat, group=id, fill=Pop_Scale))+geom_polygon(colour="black")+coord_map()
ColorNum=length(unique(Pop_Map$Pop_Scale)) #计算看需要多少种颜色
mymap+scale_fill_manual(values=colorRampPalette(c("blue","green", "red"))(ColorNum))
mymap+scale_fill_manual(values=colorRampPalette(c("lightgoldenrod1", "red3"))(ColorNum))
mymap+scale_fill_manual(values=colorRampPalette(brewer.pal(9, "Greens"))(ColorNum))
library(ggplot2)
library(plyr)
library(RColorBrewer)
library(Hmisc) #needed for cut2
library(dplyr) #needed for %>%, group_by and summarise
#setwd("D:/BA/CHNMap")
#例子1
CHNGDP_Rate <-read.csv("GDPRate.csv")
CHNmapdata<-read.csv("ProvMapData.csv")
ProvIndex<-read.csv("ProvIndex.csv")
GDP_Index <-merge(CHNGDP_Rate,ProvIndex,by="ProvNames")
GDP_Index <-arrange(GDP_Index,ProvID)
GDP_Map <- merge(CHNmapdata,GDP_Index,by.x="id",by.y="ProvID")
#合并GDP_Index和CHNmapdata，这样Mapdata中每个id就有Data列中的人口数据对应
GDP_Map <- arrange(GDP_Map,id,order) #经过合并操作之后数据被打乱，需要重新排序。
#先对id进行排序，然后对order进行排序
head(GDP_Map)
ggplot(GDP_Map, aes(x=long, y=lat, group=id, fill=GDP_Rate))+geom_polygon(colour="black")+coord_map()
#将GDP增速切割为5类。
install.packages("dplyr")
install.packages("Hmisc")
library(ggplot2)
library(plyr)
library(RColorBrewer)
library(Hmisc) #needed for cut2
library(dplyr) #needed for %>%, group_by and summarise
#setwd("D:/BA/CHNMap")
#例子1
CHNGDP_Rate <-read.csv("GDPRate.csv")
CHNmapdata<-read.csv("ProvMapData.csv")
ProvIndex<-read.csv("ProvIndex.csv")
GDP_Index <-merge(CHNGDP_Rate,ProvIndex,by="ProvNames")
GDP_Index <-arrange(GDP_Index,ProvID)
GDP_Map <- merge(CHNmapdata,GDP_Index,by.x="id",by.y="ProvID")
#合并GDP_Index和CHNmapdata，这样Mapdata中每个id就有Data列中的人口数据对应
GDP_Map <- arrange(GDP_Map,id,order) #经过合并操作之后数据被打乱，需要重新排序。
#先对id进行排序，然后对order进行排序
head(GDP_Map)
ggplot(GDP_Map, aes(x=long, y=lat, group=id, fill=GDP_Rate))+geom_polygon(colour="black")+coord_map()
CHNGDP_Rate <-read.csv("GDPRate.csv")
CHNmapdata<-read.csv("ProvMapData.csv")
ProvIndex<-read.csv("ProvIndex.csv")
GDP_Index <-merge(CHNGDP_Rate,ProvIndex,by="ProvNames")
GDP_Index <-arrange(GDP_Index,ProvID)
GDP_Map <- merge(CHNmapdata,GDP_Index,by.x="id",by.y="ProvID")
#合并GDP_Index和CHNmapdata，这样Mapdata中每个id就有Data列中的人口数据对应
GDP_Map <- arrange(GDP_Map,id,order) #经过合并操作之后数据被打乱，需要重新排序。
#先对id进行排序，然后对order进行排序
head(GDP_Map)
ggplot(GDP_Map, aes(x=long, y=lat, group=id, fill=GDP_Rate))+geom_polygon(colour="black")+coord_map()
AA <- cut2(CHNGDP_Rate$GDP_Rate,g=5)
AA <- data.frame(MyLevels = AA)
AA %>% group_by(MyLevels) %>% summarise(no_rows = length(MyLevels))
AA <- cut2(CHNGDP_Rate$GDP_Rate,g=5,onlycuts = TRUE) #切割成5份，但是返回切割点而不是切割结果。
AA[1]=AA[1]-0.1  #由于左边是开区间右边是闭区间，为了保证数据最小值也被考虑到，需要把最小切割点稍稍往下移。
GDP_Map$GDPRate_Scale <- cut(GDP_Map$GDP_Rate,breaks=AA)
ggplot(GDP_Map, aes(x=long, y=lat, group=id, fill=GDPRate_Scale))+geom_polygon(colour="black")+coord_map()
CHNPop <-read.csv("ProvData.csv") #在ProvNames工作表中填入数字（本例为人口密度）然后另存为ProvData.csv
CHNmapdata<-read.csv("ProvMapData.csv")
ProvIndex<-read.csv("ProvIndex.csv")
Pop_Index <-merge(CHNPop,ProvIndex,by="ProvNames")
Pop_Index <-arrange(Pop_Index,ProvID)
Pop_Index <-transform(Pop_Index, ProvNames=NULL) #Pop_Index中的ProvNames对我们没用了，可以把这列删掉。
Pop_Map <- merge(CHNmapdata,Pop_Index,by.x="id",by.y="ProvID")
Pop_Map <- arrange(Pop_Map,id,order) #经过合并操作之后数据被打乱，需要重新排序。
head(Pop_Map)
ggplot(Pop_Map, aes(x=long, y=lat, group=id, fill=PopData))+geom_polygon(colour="black")+coord_map()
Pop_Map$Pop_Scale <- cut(Pop_Map$PopData,breaks=c(0,50,150,250,300,400,600,1000,20000))
mymap <- ggplot(Pop_Map, aes(x=long, y=lat, group=id, fill=Pop_Scale))+geom_polygon(colour="black")+coord_map()
mymap
mymap+scale_fill_brewer(palette="Reds")
mymap+scale_fill_brewer(palette="Greens")
Pop_Map$Pop_Scale <- cut(Pop_Map$PopData,breaks=c(0,50,100,150,250,300,400,500,600,700,800,1000,20000))
mymap <- ggplot(Pop_Map, aes(x=long, y=lat, group=id, fill=Pop_Scale))+geom_polygon(colour="black")+coord_map()
ColorNum=length(unique(Pop_Map$Pop_Scale)) #计算看需要多少种颜色
mymap+scale_fill_manual(values=colorRampPalette(c("blue","green", "red"))(ColorNum))
mymap+scale_fill_manual(values=colorRampPalette(c("lightgoldenrod1", "red3"))(ColorNum))
setwd("D:/workspace_r/HW04")
library(ggplot2)
install.packages("ggplot2")
library(plyr)
library(RColorBrewer)
library(Hmisc)
install.packages("Hmisc")
library(dplyr)
install.packages("dplyr")
library("ggplot2", lib.loc="D:/PROF/R/R-3.4.0/library")
library("plyr", lib.loc="D:/PROF/R/R-3.4.0/library")
library(RColorBrewer)
library(Hmisc)
library(dplyr)
install.packages("dplyr")
library(dplyr)
Sales <-read.csv("ProvSales.csv")
CHNmapdata<-read.csv("ProvMapData.csv")
ProvIndex<-read.csv("ProvIndex.csv")
Sales_Index <-merge(Sales,ProvIndex,by="ProvNames")
Sales_Index <-arrange(Sales_Index,ProvID)
Sales_Map <- merge(CHNmapdata,Sales_Index,by.x="id",by.y="ProvID")
Sales_Map <- arrange(Sales_Map,id,order) #经过合并操作之后数据被打乱，需要重新排序。
head(Sales_Map)
ggplot(Sales_Map, aes(x=long, y=lat, group=id, fill=GDP_Rate))+geom_polygon(colour="black")+coord_map()
ggplot(Sales_Map, aes(x=long, y=lat, group=id, fill=ProvSales))+geom_polygon(colour="black")+coord_map()
install.packages("mapproj")
ggplot(Sales_Map, aes(x=long, y=lat, group=id, fill=ProvSales))+geom_polygon(colour="black")+coord_map()
ggplot(Sales_Map, aes(x=long, y=lat, group=id, fill=ProvSales))+geom_polygon(colour="green")+coord_map()
ggplot(Sales_Map, aes(x=long, y=lat, group=id, fill=ProvSales),colour = "green")+geom_polygon(colour="black")+coord_map()
ggplot(Sales_Map, aes(x=long, y=lat, group=id, fill=ProvSales,colour = "green"))+geom_polygon(colour="black")+coord_map()
Sales_Map$SScale<- cut(Sales_Map$ProvSales,breaks=c(0,3000,6000,12000,22000,26000,32000,42000))
mymap
mymap <- ggplot(Sales_Map, aes(x=long, y=lat, group=id, fill=SScale))+geom_polygon(colour="black")+coord_map()
mymap
mymap+scale_fill_brewer(palette="Greens")
library(XML)
install.packages("xml")
install.packages("XML")
library(XML)
url = 'http://www.thepaper.cn/' #澎湃新闻的URL。
doc = htmlParse(url)  #提取网页源代码
xpathSApply(doc, "//*[@id='listhot0']/li/a",xmlValue)
xpathSApply(doc, "//*[@id='listhot1']/li/a",xmlValue)
xpathSApply(doc, "//*[@id='listhot2']/li/a",xmlValue)
(oneday<-xpathSApply(doc, "//*[@id='listhot0']/li/a",xmlValue))
rm(oneday)
url = 'http://www.jiemian.com/lists/32.html' #界面新闻天下栏目的URL。
doc = htmlParse(url)  #提取网页源代码
xpathSApply(doc, "//*[@id='load-list']/div[1]/div[2]/div[2]/h3/a",xmlValue)
xpathSApply(doc, "//*[@id='load-list']///h3/a",xmlValue)
xpathSApply(doc, "//*[@id='load-list']//h3/a",xmlValue)
xpathSApply(doc, "//*[@id='load-list']//h3/a.href",xmlValue)
xpathSApply(doc, "//*[@id='load-list']//h3/a/href",xmlValue)
xpathSApply(doc, "//*[@id='load-list']//h3/a",xmlValue)
?xpathSApply()
xpathSApply(doc, "//*[@id='load-list']//h3/a",xmlValue)
xpathSApply(doc, "//*[@id='load-list']",xmlGetAttr, "data-url")
xpathSApply(doc, "//*[@id='load-list']//h3/a.href",xmlGetAttr, "data-url")
a.title
xpathSApply(doc, "//*[@id='load-list']//h3/a.href",xmlGetAttr, "data-url")
xpathSApply(doc, "//*[@id='load-list']//h3/a.href",xmlValue)
xpathSApply(doc, "//*[@id='load-list']//h3/a",xmlGetAttr, "href")
install.packages("fpp")
library(fpp)
data(euretail)
data(euretail)
fit <- decompose(euretail, type="multiplicative")
plot(fit)
?decompose
fit <- decompose(euretail, type="addtive")
fit <- decompose(euretail, type="additive")
plot(fit)
fit <- decompose(euretail, type="multiplicative")
plot(fit)
?hw
fit1<-hw(euretail, seasonal="additive")
fit2<-hw(euretail, seasonal="multiplicative")
mult_fit <- decompose(euretail, type="multiplicative")
plot(mult_fit)
add_fit <- decompose(euretail, type="additive")
plot(add_fit)
fit1<-hw(euretail, seasonal="additive")
fit2<-hw(euretail, seasonal="multiplicative")
rm(fit)
plot(fit1)
plot(fit2)
plot(fit1)
plot(fit2)
plot(fit2,ylab="Quaterly Retail Trade Index in the Euro Area",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
plot(fit2,ylab="Quaterly Retail Trade Index in the Euro Area",
type="o", fcol="white", xlab="Year")
plot(fit2,ylab="Quaterly Retail Trade Index in the Euro Area",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
plot(fit2,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
?plot
plot(fit2,ylab="Retail Index",
type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(fit2,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
legend("topleft",lty=1, pch=1, cex=0.5,col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(fit2,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1, cex=0.5,col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(fit2,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(fit2,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1,cex=0.8, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(fit2,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1,cex=0.5, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(euretail,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1,cex=0.5, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
warnings()
plot(euretail,ylab="Retail Index",type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1,cex=0.5, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(euretail,ylab="Retail Index",type="o", fcol="white", xlab="Year",ylim = c(1900,2020))
warnings()
plot(euretail,ylab="Retail Index",type="o",fcol="white", xlab="Year",ylim = c(1900,2020))
plot(euretail,ylab="Retail Index",type="o",fcol="white", xlab="Year"))
plot(euretail,ylab="Retail Index",type="o", fcol="white", xlab="Year")
plot(euretail,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
warnings()
library(fpp)
data(euretail)
mult_fit <- decompose(euretail, type="multiplicative")
plot(mult_fit)
add_fit <- decompose(euretail, type="additive")
plot(add_fit)
fit1<-hw(euretail, seasonal="additive")
fit2<-hw(euretail, seasonal="multiplicative")
plot(euretail,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
plot(euretail,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year")
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1,cex=0.5, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(euretail,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year",ylim=c(1990,2020))
plot(euretail,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year",xlim=c(1990,2020))
plot(euretail,ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year",xlim=c(1995,2015))
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1,cex=0.5, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
plot(euretail,main='Quaterly Retail Trade Index in the Euro Area',ylab="Retail Index",
plot.conf=FALSE, type="o", fcol="white", xlab="Year",xlim=c(1995,2015))
lines(fitted(fit1), col="red", lty=2)
lines(fitted(fit2), col="green", lty=2)
lines(fit1$mean, type="o", col="red")
lines(fit2$mean, type="o", col="green")
legend("topleft",lty=1, pch=1,cex=0.5, col=1:3,
c("data","Holt Winters' Additive","Holt Winters'
Multiplicative"))
library("survival", lib.loc="D:/PROF/R/R-3.4.0/library")
warnings(
)
install.packages("OIsurv")
install.packages(c("foreign", "glue", "Matrix", "XML"))
hiv<-read.csv('Hmohiv.csv',header=TRUE)
setwd("D:/workspace_r/HW04")
View(hiv)
my.surv<-Surv(time,status)
attach(hiv)
my.surv<-Surv(time,status)
library(survival)
library(OIsurv)
my.surv<-Surv(time,status)
my.fit<-survfit(my.surv~1)   #Kaplan-Meier
summary(my.fit)
plot(my.fit)
my.fit1<-survfit(Surv(time,status)~drug)
plot(my.fit1)
plot(my.fit)
urvdiff(Surv(time, status) ~ drug)
survdiff(Surv(time, status) ~ drug)
detach(hiv)
library(survival)
library(OIsurv)
data(tongue)
attach(tongue)
my.surv<-Surv(time, delta)
#这里是right censored数据，所以type='right'。
#delta取值为1代表事件发生（例如死亡），取值为0则代表右截值。
my.fit<-survfit(my.surv~1)   #Kaplan-Meier
summary(my.fit)
plot(my.fit)
#比较type=1和type=2这两个组的存活函数
my.fit1<-survfit(Surv(time,delta)~type)
plot(my.fit1)
H.hat<--log(my.fit$surv)
H.hat<-c(H.hat, tail(H.hat,1))
print(my.fit, print.rmean=TRUE)
survdiff(Surv(time, delta) ~ type) # 在5%水平上并没有显著区别。
library(XML)
url = 'http://amf.bz/imouto/yuri-takase-t37285.html'
doc = htmlParse(url)
xpathSApply(doc, "//*[@id="p174615"]/div/div[1]/div[1]",xmlGetAttr, "href")
xpathSApply(doc, "//*[@id=\"p174615\"]/div/div[1]/div[1]",xmlGetAttr, "href")
xpathSApply(doc, "//div/div[1]/div[1]",xmlGetAttr, "href")
xpathSApply(doc, "//*[@id=\"p174615\"]/div/div[1]/div[1]/a[63]",xmlGetAttr, "href")
xpathSApply(doc, "//*[@id=\"p174615\"]/div/div[1]/div[1]/a[*]",xmlGetAttr, "href")
xpathSApply(doc, "//*[@id=\"p174615\"]/div/div[1]/div[1]/a[64]",xmlGetAttr, "href")
?xpathSApply
xpathSApply(doc, "//*[@id=\"p174615\"]/div/div[1]/div[1]/a",xmlGetAttr, "href")
links<-xpathSApply(doc, "//*[@id=\"p174615\"]/div/div[1]/div[1]/a",xmlGetAttr, "href")
links
links[63:]
links[63:115]
links<-links[63:115]
links
?substr
substr(links[],'h','?')
substr(links[1],'h','?')
links<-xpathSApply(doc, "//*[@id=\"p174615\"]/div/div[1]/div[1]/a",xmlGetAttr, "href")
links<-links[63:115]
links[1]
class(links[1])
substring(links[1],'h','?')
substring(links[1],1,2)
nchar(links[1])
substring(links[1],19,109)
substring(links[],19,109)
link_get<-substring(links[],19,109)
sink('xxx.txt')
(link_get)
sink()
write.table(link_get,'xxx.txt')
?write.table
write.table(link_get,'xxx.txt',quote =FALSE)
write.table(link_get,'xxx.txt',quote =FALSE)
write.table(link_get,'xxx.txt',quote =FALSE,row.names =FALSE)
